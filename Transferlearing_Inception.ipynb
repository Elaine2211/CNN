{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transferlearing_Fangyi Yu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elaine2211/CNN/blob/master/Transferlearing_Inception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "outputId": "da97fcfb-761d-4d21-b672-0df24d9cef5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "35e2c6ba-0940-40ec-b1b2-f7df50752e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-30 18:53:55--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c12::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   122MB/s    in 0.7s    \n",
            "\n",
            "2020-01-30 18:53:56 (122 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "86fa581e-98ca-4ada-8379-3392ab9c72e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "fce8948f-a295-4b67-a092-438ac975cdd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "9b1aaaef-e0cf-453b-ca9e-fa8632871389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-30 18:54:14--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c12::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   188MB/s    in 0.8s    \n",
            "\n",
            "2020-01-30 18:54:15 (188 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2020-01-30 18:54:15--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.194.128, 2607:f8b0:4001:c12::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.194.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-01-30 18:54:15 (130 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "8161686f-3879-4225-9dc4-43fc1f6c41da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') \n",
        "train_humans_dir = os.path.join(train_dir, 'humans')\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') \n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "ab0585af-78b6-48cf-95c0-35c4ec3ba674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Add data-augmentation parameters to ImageDataGenerator to decrease overfitting\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# The validation data should not be augmented\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "1778852d-2344-4699-b26f-43d17dcc1f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "100/100 - 37s - loss: 0.1963 - acc: 0.9220 - val_loss: 0.0029 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0692 - acc: 0.9721 - val_loss: 0.0056 - val_acc: 0.9960\n",
            "Epoch 3/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0473 - acc: 0.9833 - val_loss: 0.0333 - val_acc: 0.9960\n",
            "Epoch 4/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0505 - acc: 0.9844 - val_loss: 0.0210 - val_acc: 0.9960\n",
            "Epoch 5/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0471 - acc: 0.9868 - val_loss: 0.0693 - val_acc: 0.9838\n",
            "Epoch 6/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0355 - acc: 0.9883 - val_loss: 0.0485 - val_acc: 0.9919\n",
            "Epoch 7/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0236 - acc: 0.9914 - val_loss: 0.1642 - val_acc: 0.9767\n",
            "Epoch 8/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0304 - acc: 0.9894 - val_loss: 0.1278 - val_acc: 0.9838\n",
            "Epoch 9/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0233 - acc: 0.9919 - val_loss: 0.1080 - val_acc: 0.9919\n",
            "Epoch 10/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0277 - acc: 0.9913 - val_loss: 0.4035 - val_acc: 0.9615\n",
            "Epoch 11/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0324 - acc: 0.9935 - val_loss: 0.0811 - val_acc: 0.9899\n",
            "Epoch 12/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0261 - acc: 0.9919 - val_loss: 0.3456 - val_acc: 0.9676\n",
            "Epoch 13/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0237 - acc: 0.9939 - val_loss: 0.1944 - val_acc: 0.9798\n",
            "Epoch 14/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0308 - acc: 0.9919 - val_loss: 0.4657 - val_acc: 0.9575\n",
            "Epoch 15/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0231 - acc: 0.9939 - val_loss: 0.3480 - val_acc: 0.9706\n",
            "Epoch 16/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0300 - acc: 0.9924 - val_loss: 0.1860 - val_acc: 0.9798\n",
            "Epoch 17/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0187 - acc: 0.9955 - val_loss: 0.3709 - val_acc: 0.9595\n",
            "Epoch 18/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0233 - acc: 0.9944 - val_loss: 0.1661 - val_acc: 0.9828\n",
            "Epoch 19/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0240 - acc: 0.9944 - val_loss: 0.7202 - val_acc: 0.9443\n",
            "Epoch 20/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0238 - acc: 0.9944 - val_loss: 0.4827 - val_acc: 0.9575\n",
            "Epoch 21/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0191 - acc: 0.9939 - val_loss: 0.2631 - val_acc: 0.9717\n",
            "Epoch 22/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0112 - acc: 0.9965 - val_loss: 0.9186 - val_acc: 0.9504\n",
            "Epoch 23/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0192 - acc: 0.9959 - val_loss: 0.2683 - val_acc: 0.9757\n",
            "Epoch 24/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0207 - acc: 0.9950 - val_loss: 0.3461 - val_acc: 0.9656\n",
            "Epoch 25/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0076 - acc: 0.9980 - val_loss: 0.4953 - val_acc: 0.9565\n",
            "Epoch 26/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0182 - acc: 0.9965 - val_loss: 0.7851 - val_acc: 0.9504\n",
            "Epoch 27/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0204 - acc: 0.9959 - val_loss: 0.3298 - val_acc: 0.9727\n",
            "Epoch 28/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0219 - acc: 0.9944 - val_loss: 0.2215 - val_acc: 0.9858\n",
            "Epoch 29/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0153 - acc: 0.9954 - val_loss: 0.5266 - val_acc: 0.9555\n",
            "Epoch 30/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0115 - acc: 0.9975 - val_loss: 0.7451 - val_acc: 0.9524\n",
            "Epoch 31/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0031 - acc: 0.9990 - val_loss: 0.6656 - val_acc: 0.9545\n",
            "Epoch 32/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0180 - acc: 0.9944 - val_loss: 0.6453 - val_acc: 0.9565\n",
            "Epoch 33/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0053 - acc: 0.9980 - val_loss: 0.3336 - val_acc: 0.9717\n",
            "Epoch 34/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0230 - acc: 0.9934 - val_loss: 0.5515 - val_acc: 0.9626\n",
            "Epoch 35/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0083 - acc: 0.9980 - val_loss: 0.3131 - val_acc: 0.9777\n",
            "Epoch 36/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0089 - acc: 0.9975 - val_loss: 0.6019 - val_acc: 0.9555\n",
            "Epoch 37/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0027 - acc: 0.9990 - val_loss: 0.6014 - val_acc: 0.9555\n",
            "Epoch 38/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0241 - acc: 0.9959 - val_loss: 0.7735 - val_acc: 0.9484\n",
            "Epoch 39/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0090 - acc: 0.9975 - val_loss: 0.8883 - val_acc: 0.9453\n",
            "Epoch 40/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0054 - acc: 0.9980 - val_loss: 0.9247 - val_acc: 0.9453\n",
            "Epoch 41/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0389 - acc: 0.9954 - val_loss: 1.6833 - val_acc: 0.9231\n",
            "Epoch 42/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0124 - acc: 0.9975 - val_loss: 0.6866 - val_acc: 0.9555\n",
            "Epoch 43/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0043 - acc: 0.9985 - val_loss: 1.1771 - val_acc: 0.9474\n",
            "Epoch 44/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0245 - acc: 0.9960 - val_loss: 0.6774 - val_acc: 0.9474\n",
            "Epoch 45/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0116 - acc: 0.9954 - val_loss: 0.5579 - val_acc: 0.9626\n",
            "Epoch 46/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0090 - acc: 0.9985 - val_loss: 1.1183 - val_acc: 0.9433\n",
            "Epoch 47/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0133 - acc: 0.9975 - val_loss: 1.3797 - val_acc: 0.9413\n",
            "Epoch 48/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0119 - acc: 0.9969 - val_loss: 1.7150 - val_acc: 0.9362\n",
            "Epoch 49/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0142 - acc: 0.9955 - val_loss: 1.1667 - val_acc: 0.9443\n",
            "Epoch 50/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0145 - acc: 0.9954 - val_loss: 2.1895 - val_acc: 0.9140\n",
            "Epoch 51/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0061 - acc: 0.9985 - val_loss: 1.4519 - val_acc: 0.9453\n",
            "Epoch 52/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0106 - acc: 0.9975 - val_loss: 1.5129 - val_acc: 0.9433\n",
            "Epoch 53/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0192 - acc: 0.9949 - val_loss: 1.3466 - val_acc: 0.9413\n",
            "Epoch 54/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0125 - acc: 0.9965 - val_loss: 1.6610 - val_acc: 0.9423\n",
            "Epoch 55/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0222 - acc: 0.9959 - val_loss: 0.9562 - val_acc: 0.9545\n",
            "Epoch 56/100\n",
            "Epoch 1/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 25s - loss: 5.8652e-04 - acc: 1.0000 - val_loss: 0.8405 - val_acc: 0.9545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "9dd00eaa-0a67-479b-ee46-483206e80821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVaffV7qzREr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}